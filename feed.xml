<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ychen884.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ychen884.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-01-23T02:56:44+00:00</updated><id>https://ychen884.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Distributed Systems Notes - Currently Upating…</title><link href="https://ychen884.github.io/blog/2024/15640/" rel="alternate" type="text/html" title="Distributed Systems Notes - Currently Upating…"/><published>2024-01-18T11:00:00+00:00</published><updated>2024-01-18T11:00:00+00:00</updated><id>https://ychen884.github.io/blog/2024/15640</id><content type="html" xml:base="https://ychen884.github.io/blog/2024/15640/"><![CDATA[<h3 id="course-evaluation-final-grade-na">Course Evaluation (Final grade: N/A)</h3> <p>I will add my course evaluation at the end of this semester.</p> <h3 id="paper-reviews">Paper reviews</h3> <p>I will upload my paper reviews here later.</p> <h2 id="blog-chapters"><strong>Blog Chapters</strong></h2> <ol> <li><a href="#topic-1">Chapter 1: Remote Procedure Call (RPC)</a></li> <li><a href="#topic-2">Chapter 2: </a></li> <li><a href="#topic-3">Chapter 3: </a></li> <li><a href="#topic-4">Chapter 4: </a></li> <li><a href="#topic-5">Chapter 5: </a></li> <li><a href="#topic-6">Chapter 6: </a></li> <li><a href="#topic-7">Chapter 7: </a></li> </ol> <h2 id="-chapter-1-remote-procedure-call-rpc--">** Chapter 1: Remote Procedure Call (RPC) ** <a name="topic-1"></a></h2> <ul> <li>Try to fake procedure call to local programming</li> <li>Why? bring down programming complexity for distributed systems</li> <li>client-server model, per interface</li> <li>two aspects: control flow, invocation syntax</li> <li>with network delays (theoretically best at speed of light)</li> </ul> <h5 id="limitations-of-rpc">limitations of RPC</h5> <ol> <li>No address space sharing between client and server, can’t sharing pointers(call by reference), can’t share global data..</li> <li>Delayed binding in RPC</li> </ol> <h5 id="failure-independence">Failure independence</h5> <ul> <li>caller and callee live and die together in local setup</li> <li>we can witness failure case but hard to do in local</li> <li>failure handling consider visibility of failure</li> <li>Security: different domains</li> </ul> <h5 id="typical-rpc">Typical RPC</h5> <ul> <li>client: makerpc(request_packet, &amp;reply_packet): blocks until reply or failure</li> <li>server: getrequest(&amp;request_packet) blocks until receives request, sendresponse(reply_packet)</li> </ul> <h5 id="stub-routines">Stub routines</h5> <ul> <li>generated by stub generator</li> <li> <p>sit between high level purpose and low level network packing/unpacking send/recv.. ``` -&gt; : local procedure call —-: network communication</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  Client                                             Server App -&gt; Stub -&gt; Transport -----Network Com------ Transport -&gt; Stub -&gt; App
</code></pre></div> </div> </li> </ul> <p>App calls Stub Stub pack/unpack Transport transmit/receive Server App do actual work then return Packing and unpacking is usually not elastic in dev env Correctness and API design is more important</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Marshalling/Unmarshalling, Serialization/De-serialization

##### RPC packet format
1. Network transport header(Ethernet, IP, Transport(TCP/UDP))
2. RPC header
</code></pre></div></div> <p>RPC Version ID Opcode (Stub) Flags parameters + Len</p> <p>```</p> <h5 id="stub-with-dynamically-allocated-buffer">Stub with dynamically allocated buffer</h5> <ul> <li>variable to indicate how many bytes in coming</li> <li>malloc for new memories &lt;!– Project 1 Transparant Remote File Operations writing ur own RPC interfaces</li> </ul> <p>–&gt; <a href="#blog-chapters">Back to Blog Chapters</a></p> <p><a href="#blog-chapters">Back to Blog Chapters</a></p>]]></content><author><name></name></author><category term="Study"/><category term="CMU"/><summary type="html"><![CDATA[Distributed Systems Notes - SCS]]></summary></entry><entry><title type="html">Compiler Design Notes - Currently Upating…</title><link href="https://ychen884.github.io/blog/2024/15661/" rel="alternate" type="text/html" title="Compiler Design Notes - Currently Upating…"/><published>2024-01-18T11:00:00+00:00</published><updated>2024-01-18T11:00:00+00:00</updated><id>https://ychen884.github.io/blog/2024/15661</id><content type="html" xml:base="https://ychen884.github.io/blog/2024/15661/"><![CDATA[ <h3 id="course-evaluation-final-grade-na">Course Evaluation (Final grade: N/A)</h3> <p>I will add my course evaluation at the end of this semester.</p> <h3 id="paper-reviews">Paper reviews</h3> <p>I will upload my paper reviews here later.</p> <h2 id="blog-chapters"><strong>Blog Chapters</strong></h2> <ol> <li><a href="#topic-1">Chapter 0: Overview of Compiler Design</a></li> <li><a href="#topic-1.1">Chapter 1: Instruction Selection</a></li> <li><a href="#topic-2">Chapter 2: Register Allocation</a></li> </ol> <h2 id="chapter-1-overview-of-compiler-design--">**Chapter 1: Overview of Compiler Design ** <a name="topic-1"></a></h2> <h3 id="what-makes-a-good-compiler-metrics">What makes a good Compiler: metrics</h3> <ul> <li>correctness</li> <li>code quality: compiled code runs fast</li> <li>efficiency: compilation runs fast</li> <li>usability: provides errors/warnings, …</li> </ul> <h3 id="compiler-design">Compiler Design</h3> <ul> <li>structure compilers</li> <li>applied alg &amp; data structures</li> <li>focus on sequential imperative programming languages</li> <li> <ul> <li>not functional, parallel, distributed, OOP…</li> </ul> </li> <li>code generation and optimization</li> </ul> <h3 id="organizing-a-compiler">Organizing a compiler</h3> <h4 id="front">Front</h4> <ul> <li>split work into different phases</li> <li>Lexical analysis -&gt; Token stream</li> <li>Parsing -&gt; Abstract syntax tree (mark body of while loop…)</li> <li>Sementic analysis (type check, variable initialization)</li> </ul> <h4 id="middle">Middle</h4> <ul> <li>IR(intermediate representation) Generation -&gt; Intermediate representations</li> <li>Optimize (most challenging)</li> </ul> <h4 id="back">Back</h4> <ul> <li>Instruction selection -&gt; Abstract assembly</li> <li>Register allocation -&gt; ASM Middle and Back has unclear distinctions</li> </ul> <p><a href="#blog-chapters">Back to Blog Chapters</a></p> <h2 id="chapter-11-instruction-selection--">**Chapter 1.1: Instruction Selection ** <a name="topic-1.1"></a></h2> <ul> <li>Compiler phase</li> <li>IR tree -&gt; abstract assembly</li> </ul> <p>Example:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x = 5
return x+x+x*2

-&gt;&gt;&gt; Instruction selection
x = 5
temp1 = x + x 
temp2 = x * 2
ret_reg = t1 + t2
ret
</code></pre></div></div> <h5 id="ir-tree-more-expressions-statements">IR tree (more expressions, statements..)</h5> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Programs p ::= s1,...sn (sequence of statements)
statements s ::= x = e 
                return e

Expressions:
e ::= c int const
      x variable
      e1 ⊕ e2 binary OP (nested)
      ⊕ ::= +1 * 1 / 1 ...
</code></pre></div></div> <h5 id="abstract-assembly-flat">Abstract Assembly (flat)</h5> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Program: p ::= i1, ... in (instructions)
Instructions i::= d &lt;- s move
                = d &lt;- s1 ⊕ s2 bin op (sometimes one of the source works as dst)
                = ret return
Operands:
    d,s ::= r register (usually* finite numbers as defined)
          = c int const
          = t temps (variables)
          = x var

</code></pre></div></div> <h5 id="translations-expr">Translations Expr</h5> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>translate(e1 ⊕ e2) = translate(e1); translate(e2);
res1 ⊕ res2?
Better: 
trans(d,e): seq of instructions that stores value of e in destination d. 


e           trans(d,e)
x           d &lt;- x
c           d &lt;- c
e1 ⊕ e2     trans(t1, e1), trans(t2, e2), d&lt;-t1⊕t2, (t1 and t2 are fresh temps)


</code></pre></div></div> <h5 id="translate-statements">Translate statements</h5> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>trans'(s): seq of instru that inlements s
s           trans'(s)
x = e       trans(x,e)
return e    trans(ret,e) return (ret: return register)
</code></pre></div></div> <h5 id="example">Example</h5> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>IR prog: 
z = (x + 1) * (y * 4)
return z

trans'(p) 
= trans'(z = (x + 1) * (y * 4)), trans'(return z)
= trans(z,(x + 1) * (y * 4)),trans(ret, z), return
= trans(t1,x+1), trans(t2,y * 4), z&lt;- t1 * t2, ret&lt;-z, return
= t3 &lt;- x, t4 &lt;- 1, t1 &lt;- t3 + t4, t5 &lt;- y, t6 &lt;- 4, t2 &lt;- t5 * t6, z &lt;- t1*t2, ret&lt;-z, return
Optimize? directly use x and y instead of moving them to temps

</code></pre></div></div> <h5 id="how-to-improve">How to improve</h5> <ol> <li>Add special cases: for example c ⊕ e2</li> <li>Optimization pass after the first pass of translation (common approach)</li> <li>Different translation</li> </ol> <h5 id="constant-propagation">Constant propagation</h5> <ul> <li>goal: eliminate move t &lt;- c, p by replacing t with c in p</li> <li>But: stop replacing t if it’s written again <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Example: 
t &lt;- 4
x &lt;- t+1   ---&gt; x &lt;- 4+1 
t &lt;- 5
ret &lt;- t   --NO--&gt; ret &lt;- 4
return 
</code></pre></div> </div> </li> </ul> <h5 id="copy-propagation">Copy propagation</h5> <ul> <li>goal: elim move d &lt;- t,p by replacing d with t in p</li> <li>But: step replacing if d is written or if t is written <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>t &lt;- 5+1
d &lt;- t 
x &lt;- d+1 ----&gt; x &lt;- t+1
t &lt;- 5+2
ret &lt;- d+1 ----No---&gt; ret &lt;- t + 1
ret
</code></pre></div> </div> </li> </ul> <h5 id="static-single-assignment-form">Static Single Assignment Form</h5> <ul> <li>every temp is assigned at most once</li> <li>don’t have to check “writes” but can replace all occurances in propagations</li> <li>Conversion to SSA -&gt; user version nums ``` t &lt;- 5+1 d &lt;- t x &lt;- d+1 —-&gt; x &lt;- t+1 t &lt;- 5+2 ret &lt;- d+1 —-No—&gt; ret &lt;- t + 1 ret</li> </ul> <p>—–»</p> <p>t0 &lt;- 5+1 d0 &lt;- t0 x0 &lt;- d0+1 t1 &lt;- 5+2 … ```</p> <p><a href="#blog-chapters">Back to Blog Chapters</a></p> <h2 id="chapter-2-register-allocation--">**Chapter 2: Register Allocation ** <a name="topic-2"></a></h2> <ul> <li>Goal: assign registers and stack locations to temps <h5 id="x86-64-16-registers-no-temps">X86-64: 16 registers, no temps</h5> </li> <li>stack locations, when keeping track of more variables than registers <h5 id="strategy">Strategy</h5> <ol> <li>Store all temps on the stack (CON: inefficient, still need registers for efficiency)</li> </ol> </li> </ul> <p><a href="#blog-chapters">Back to Blog Chapters</a></p>]]></content><author><name></name></author><category term="Study"/><category term="CMU"/><summary type="html"><![CDATA[Compiler Design Notes - SCS]]></summary></entry><entry><title type="html">Advanced Cloud Computing Notes - Currently Upating…</title><link href="https://ychen884.github.io/blog/2024/15719/" rel="alternate" type="text/html" title="Advanced Cloud Computing Notes - Currently Upating…"/><published>2024-01-16T11:00:00+00:00</published><updated>2024-01-16T11:00:00+00:00</updated><id>https://ychen884.github.io/blog/2024/15719</id><content type="html" xml:base="https://ychen884.github.io/blog/2024/15719/"><![CDATA[<h3 id="course-evaluation-final-grade-na">Course Evaluation (Final grade: N/A)</h3> <p>I will add my course evaluation at the end of this semester.</p> <h2 id="blog-chapters"><strong>Blog Chapters</strong></h2> <ol> <li><a href="#topic-1">Chapter 1: Overview of Cloud Computing</a></li> <li><a href="#topic-2">Chapter 2: </a></li> <li><a href="#topic-3">Chapter 3: </a></li> <li><a href="#topic-4">Chapter 4: </a></li> <li><a href="#topic-5">Chapter 5: </a></li> <li><a href="#topic-6">Chapter 6: </a></li> <li><a href="#topic-7">Chapter 7: </a></li> </ol> <h2 id="-chapter-1-overview-of-cloud-computing--">** Chapter 1: Overview of Cloud Computing ** <a name="topic-1"></a></h2> <h4 id="definitions">Definitions</h4> <h5 id="properties">Properties:</h5> <ul> <li>Computing utility, always available, accessible through the networks</li> <li>Simplified interface</li> <li>Statistical multiplexing, sharing resources</li> <li>Economies of scale from consolidation, costs lower</li> <li>Capital costs converted to operating costs</li> <li>Rapid and easy variation of usage</li> <li>Appearance of infinite resources with small users</li> <li>Pay only for what you use</li> <li>Cost conservation: 1 unit for 1000 hours == 1000 units for 1 hour</li> </ul> <h5 id="consolidation-sharing-elasticity">Consolidation, sharing, elasticity</h5> <ul> <li>CLT theory</li> <li>users with widely varying needs apply a considerably less variable load on a huge provider, allowing providers to do less overprovisioning.</li> <li> <ul> <li>Because of CLT, it is predictable for the overall load which causes less overprovisioning.</li> </ul> </li> <li>Users perceive exactly what they need all the time, if their needs are “small”(so the accessed resources are appearing as infinite)</li> </ul> <h5 id="saas-paas-iaas">SaaS, PaaS, IaaS</h5> <ul> <li>SaaS: service as application (Salesforce)</li> <li> <ul> <li>consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage &amp; minimum deployed applications configurations settings.</li> </ul> </li> <li>PaaS: high-level programming model for cloud computer, Turing complete but resource management hidden. (Google AppEngine)</li> <li> <ul> <li>consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage but with control over the deployed applications and possibly configuration settings for the application-hosting environment.</li> </ul> </li> <li>IaaS: low-level computing model for cloud computer (AWS)</li> <li> <ul> <li>The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, and deployed applications</li> </ul> </li> </ul> <h5 id="xxx-as-a-service">XXX as a Service</h5> <ul> <li>Data as a Service, Network as a Service, Communication as a Service(No hardware private VOIP switching), IT as a Service(IT providing services)..</li> </ul> <h5 id="deployment-models">Deployment models</h5> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>public cloud: provider sells computing to unrelated consumers
private cloud: largely unrelated components and divisions as consumers
community cloud: providers and consumers are different organizations with strong shared concerns
Hybrid cloud: private plus public resources combined by same consumer. Better availability, overflow from private to public, load balancing to increase elasticity
</code></pre></div></div> <h5 id="larry-ellisons-objection">Larry Ellison’s objection</h5> <ul> <li>definition is including too much </li> </ul> <h5 id="obstacles-of-cloud-computing">Obstacles of cloud computing</h5> <ul> <li>Privacy &amp; security</li> <li>Privacy in the world tends to rely on regulation</li> <li>Utility issues</li> <li>Physical utilities tend to rely on regulation</li> <li>High cost of networking combined with always remote</li> <li>Performance unpredictability &amp; in situ development/debugging</li> <li>Software licensing – $/yr/CPU is not elastic and pay as you go</li> </ul> <h5 id="load-balancing-approach">load balancing approach</h5> <h5 id="1-dns-load-balancing">1. DNS load balancing</h5> <ul> <li>DNS reorder the list for each client asking for translation of name</li> <li>PRO: easy to scale, unrelated to actual TCP/HTTP requests</li> <li>CON: new server may get less resources if scheduling more servers, dynamic changing is hard because it has to tell client for a binding(existing binding exists due to TTL, caching in network middleboxes).</li> </ul> <h5 id="2-router-distribute-tcp-connections">2. Router distribute TCP connections</h5> <ul> <li>Router do the mapping: (client_ip+client_port) &lt;-&gt; (server_ip+server_port)</li> <li> <ul> <li>for SYN packets</li> </ul> </li> <li> <ul> <li>not exposed to client about the ip address(like NAT)</li> </ul> </li> <li>PRO: router doesn’t have to think or remember too much, *it just selected the server with least connnection to schedule for the new connections.</li> <li>CON: traffic all go through the router(more difficult to scale), and decision takes time cuz it’s for the entire session</li> </ul> <h4 id="3-router-distribute-individual-quests-embedded-in-connections">3. Router distribute individual quests embedded in connections</h4> <ul> <li>PRO: most dynamic</li> <li>CON: requires the most processing and state in the router, CPU load and memory goes up due to intelligent routing decisions. <h4 id="elasticit-how-elasticity-controller">Elasticit: How? Elasticity controller</h4> </li> <li>Elasticity controller to adjust load capability based on current load status</li> <li>Monitoring: resource usage, request sequence(patterns)</li> <li>Triggering: (simple conditions like thresholds), schedule, complex model based on monitored instances</li> </ul> <h4 id="elasticity-scale-out-or-scale-up">Elasticity: Scale-out or Scale up</h4> <ul> <li>Horizontal scaling: adding more instances (Common approach)</li> <li>Vertical scaling: Resizing the resources(bdw, cpu cores, memory) allocated to an existing instances, challenging(different OS.) More challenging.</li> </ul> <h4 id="two-tier-services">Two-tier services</h4> <ul> <li>web-database</li> <li>web server easy to be in cloud. At beginning, order-taking is not in cloud.</li> <li>Elasticity in IaaS: database scaling is more difficult with state(consistency)</li> <li>PassS, P=Web Service. Built-in elastic load balancing and scheduled actions for containers, persistent key-value store (datastore) &amp; non-persistent memcache for simple database tier, Users can instantiate Backends, user code can request (actuate) horizontal scaling, running traditional database services, whose scaling is still hard.</li> </ul> <h5 id="load-balancing-method-affect-how-much-statistics-we-can-get">Load-balancing method affect how much statistics we can get.</h5> <ul> <li>Router-based load balancing: firewall, intrusion detection, accelerator</li> <li>scaling middleboxes: CPU intensive tasks. (OpenFlow, split flows)</li> <li>bdw allocation by sw/rt</li> </ul> <h5 id="service-parallelization-load-balancer">Service parallelization: Load Balancer</h5> <ul> <li>aws cloud watch</li> <li>Load balancer is not necessarily elastic</li> </ul> <h5 id="scalable-relational-database">Scalable relational database</h5> <ul> <li>Separate data at rest(distributed pay-for-use storage (HDFS)) from ongoing or recent access &amp; mutation</li> <li>Recent access &amp; mutation servers are elastic (called Owning Transaction Managers)</li> <li>Partitioned but all transactions restricted to one partition: transactions block on locks and bottleneck performance scaling</li> <li>Fault-tolerance of Elastic controller. Controller itself, reliability provided by replication. Can re-assigns partitions while server is down/start up.</li> </ul> <h5 id="elastras-architecture-scales-otm-machines">ElasTraS architecture scales OTM machines</h5> <ul> <li>Transactions are limited to interacting with data from only one partition to avoid the complexity of distributed transactions.</li> <li>TODO</li> </ul> <h3 id="paper-reading-notes">Paper reading notes</h3> <ul> <li>Armbrust2010 ``` Referring to http://doi.acm.org/10.1145/1721654.1721672 Cloud computing: what brings it? large capital outlays, overprovisioning/underprovisioning…</li> </ul> <p>Definition: Refers to both the applications as services over the internet and hardware and systems software in the data center that provide those services. The services themselves: SaaS. Services being sold is utility computing. Cloud computing = SaaS + utility computing. It has to be large enough to be called cloud. Hardware provisioning/pricing: 1. inifinite computing resources available on demand; 3. elimination of an up-front commitment by cloud users, add resources when needed; 4. pay for use of computing resources temporarily. *Construction and operaition of extremely large-scale, commodify-computer data centers at low-cost locations was the key necessary enabler of cloud computing. It could offer services below the costs of a medium-sized data center and make profits.</p> <p>Utility Computing classes: EC2 with low level control but less automatic scalability and failover(application may need to control the replication…). Google AppEngine(domain specific platforms) on the other hand. Azure is in between.</p> <p>Economics: Favor cloud computing over conventional: 1. demand of services changes over time 2. demand is unknown usage based pricing economically benefits the buyer. Elasticity helps reduce the costs. Underprovisioning has a cost that is difficult to measure: the users may never come back. Scale-up elasticity is an operational requirement, and scale-down elasticity allowed the steady state expenditure to more closely match the steady-state workload.</p> <p>Obstacles for Cloud computing:</p> <p>1-3(adoption):</p> <ol> <li>Business Continuity and Service Availability (hard to ensure availability, single failure still exists for a service provider)</li> <li>Data Lock-In (public+private sharing by sharing API)</li> <li>Data Confidentiality/Auditability: from other user/provider</li> </ol> <p>4-8(growth):</p> <ol> <li>Data Transfer Bottlenecks： Applications continue to become more data-intensive</li> <li>Performance Unpredictability： I/O interference between virtual machines, concerns scheduling of virtual machines for some classes of batch processing programs, specifically for highperformance computing 6.Scalable Storage</li> <li>Bugs in Large Scale Distributed Systems: bugs cannot be reproduced in smaller configurations</li> <li>Scaling Quickly</li> </ol> <p>9-10(policy and business):</p> <ol> <li>Reputation Fate Sharing, legal liability(customer responsible-&gt;unexpected down)</li> <li>Software Licensing</li> </ol> <p>Opportunities:</p> <ul> <li>improve architectures and operating systems to efficiently virtualize interrupts and I/O channels</li> <li>flash memory will decrease I/O interference.</li> <li>offer something like “gang scheduling” for cloud computing</li> <li>create a storage system that would not only meet existing programmer expectations,but combine them with the cloud advantages of scaling arbitrarily up and down on demand.</li> <li>reliance on virtual machines in cloud computing.(7)</li> <li>automatically scale quickly up and down in response to load in order to save money</li> <li> <p>create reputation-guarding services similar to the “trusted email” services ```</p> </li> <li>Referring to NISTdef2011 ``` Characteristics:</li> <li>On-demand self-service</li> <li>Broad network access</li> <li>Rapid elasticity</li> <li> <p>Resource pooling (multi-tenant) ```</p> </li> <li>Vaquero11</li> <li>Dynamically Scaling Applications in the Cloud ``` vertical scaling is hard: rebooting.. load balancers need to support</li> </ul> <p>Server scalability: a per-tier controller, a single controller for the whole application (for all tiers) How and When to Scale: Feeding Controller with Rules and Policies</p> <ul> <li>adding load balancers</li> <li>LB scalability requires the total time taken to forward each request to the corresponding server to be negligible for small loads and should grow no faster than O(p)</li> <li>CPU-intensive web app: a LB to split computation among many instances.</li> <li>network intensive: CPU-powerful standalone instance to maximize throughput</li> <li>more network intensive applications, it may be necessary to use DNS load balancing</li> </ul> <p>Scaling the network:</p> <ul> <li>Virtualization: VLAN(L2)</li> <li>periodically measure actual network usage per application use other applications’ - increase the utilization of the network by virtually “slicing”: “network as a service”</li> <li>statistical multiplexing</li> </ul> <p>Scaling the platform: PaaS cloud platforms</p> <ul> <li>Container Scalability: execution environment for user applications.scalability of the container layer is crucial as it must efficiently manage and distribute resources to meet the demands of potentially numerous applications running concurrently.</li> </ul> <p>Multitenant containers and Isolation: requires strong isolation to prevent security issues Individual Containers per User: simplifies isolation but requires effective management of numerous containers. Horizontal Scaling via Container Replication: achieved through automatic scaling in IaaS systems or by inherent capabilities of the platform itself Components should ideally be stateless to cope with the dynamic nature of container instantiation and disposal, support for stateful components is also necessary, requiring sophisticated load balancing (LB) and container management to handle session data.(soft state replication, distributed caching systems)</p> <ul> <li>Database Scalability: for example, implementing horizontal scaling strategies, such as replicating the database across multiple nodes to handle increased load and ensure data availability. (demands on PaaS platforms can often surpass the capacity of any single machine) NoSQL Databases: These databases provide high scalability and availability, fitting well in cloud environments with high demand. However, they offer eventual consistency rather than immediate consistency, leading to limitations in transaction support and SQL functionalities. Replication Mechanisms: In-core Solutions, Middleware Solutions</li> </ul> <p>Ideal Elastic Cloud: scale through VM or container replication, reconfiguration, and dynamic load balancing, possibly using DNS for the latter. allow dynamic allocation of network resources. Ideal PaaS Platform Features: capable of instantiating or releasing instances of user components based on demand changes and distributing the load transparently among them. Implementing session concepts and supporting transparent data replication are essential. Access to traditional relational databases with ACID transaction support is crucial. However, the system must address the increased latency due to consistency maintenance across replicas, especially under high demand.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-  Infrastructure-as-Code tools provide a high-level software interface (e.g., Python / Ruby or JSON / YAML) that allows developers to specify their infrastructure requirements, software dependencies, and the process for building the infrastructure and deploying it to the cloud 

&lt;!--  --&gt;

[Back to Blog Chapters](#blog-chapters)




## ** Chapter 2: Building a CMU Cloud ** &lt;a name="topic-2"&gt;&lt;/a&gt;
#### Model
- aim for less costs

</code></pre></div></div> <p>Client -&gt; App OS Instance(s) ——————– Hypervisor (shared) Building Blocks Usage Monitor Hardware (shared) (shared Amazon EC2)</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Problem: used mostly during ddl? 2 methods, renting..
- Build a cloud
</code></pre></div></div> <ol> <li>user would rent, so provisioner(resources,monitoring,… -&gt; assignment of users to machines) <ul> <li>Bin-packing, NP-hard. Can do with assumptions.. -&gt; less complexity</li> <li>Migration, also costs</li> </ul> </li> <li>Scheduler: which user jobs/processes to run: Prioritization(pay more), Oversubscription, Workload constraints</li> <li>Encapsulation: compute, storage, networking and data</li> <li>Virtualization</li> <li>Fault tolerance: why scale of data center matters? Economy of scale, cost of operations state replication, logging, storage replic</li> </ol> <p>Storage services - Scalable, fault tolerant Tools - Programming models, frameworks Automation - Reactive systems &amp; elastic scaling</p> <p>Elastic scaling - based on monitoring and diagnosis traditional: provision for peaks</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>

- Cloud users &amp; Services
- - App user: availability, performance, no interfaces exposed by cloud service provider (app provider did that)
- - Application Deployment User: Dashboard, management interfaces exposed
- - Admin: Management...

- Orchestration: automatic deployment for user

##### OpenStack
- independent parts,6 core services
- communicate through public and well-defined APIs
- Identity -&gt; Dashboard -&gt; Compute(?)/Network -&gt; Image -&gt; Object storage(get the image for VM) -&gt; Block Storage(volume) -&gt; initiate VM
- Distributed storage to accelerate image initialization takes Azure many years to fix


- Referring to sotomayor2009
- Virtual Infrastructure Management in Private and Hybrid Clouds
</code></pre></div></div> <p>Virtual Infrastructure (VI) management in the context of private/hybrid cloud environments: Uniform Resource View, Full Lifecycle Management of VMs, Configurable Resource Allocation Policies, Adaptability to Changing Resource Needs. provides primitives to schedule and manage VMs across multiple physical hosts</p> <p>OpenNebula: This is a VI manager that allows organizations to deploy and manage VMs, either individually or in groups. It automates the VM setup process (including preparing disk images and setting up networking) and is compatible with various virtualization layers (Xen, KVM, VMware) and external clouds (EC2, ElasticHosts).</p> <p>Haizea: This acts as a lease manager and can serve as a scheduling backend for OpenNebula. It introduces leasing capabilities not present in other cloud systems, such as advance reservations and resource preemption, which are particularly valuable for private cloud environments.</p> <p>Traditional VI Management Tools: lack certain features necessary for building IaaS clouds, such as public cloud-like interfaces and the ability to deploy VMs on external clouds. Cloud toolkits can help transform existing infrastructure into an IaaS cloud with cloudlike interfaces. VI management capabilities are not as robust. -: Gap: There’s a noticeable gap between cloud management and VI management. Cloud toolkits attempt to cover both areas but often fall short in delivering comprehensive VI management functionalities. Integrating cloud management solutions with VI managers is complex due to the lack of open, standard interfaces and certain key features in existing VI managers.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>OpenNebula: overcome these challenges, Scaling to external clouds. A flexible and open architecture for easy extension and integration with other software. A variety of placement policies and support for scheduling, deploying, and configuring groups of VMs.

Integration of Haizea with OpenNebula: work as a scheduler for OpenNebula, This integration allows OpenNebula to offer resource leases as a fundamental provisioning abstraction, and Haizea to operate with real hardware through OpenNebula. This combination provides advanced features like advance reservation of capacity, which is not offered by other VI managers.

The integration is particularly beneficial for private clouds with limited resources, enabling sophisticated VM placement strategies that support queues, priorities, and advance reservations (ARs).
</code></pre></div></div> <p>OpenNebula: core: image and storage technologies for preparing disk images for VMs, network fabric (such as Dynamic Host Configuration Protocol [DHCP] servers, firewalls, or switches) for providing VMs with a virtual network environment, hypervisors for creating and controlling VMs. Performs operations through pluggable drivers. A separate scheduler component makes VM placement decisions. Management interfaces: libvirt API intergrate within other data center management tools, cloud interface exposed to external users. Cloud drivers to interface with external clouds</p> <p>The Haizea Lease Manager: Haizea is an open source resource lease manager and can act as a VM scheduler for OpenNebula. Advance Reservation (AR) Leases: Resources are guaranteed to be available at a specific future time. This is beneficial for scenarios requiring resource certainty. Best-Effort Leases: Resources are provisioned as soon as possible, with requests queued if immediate provisioning isn’t possible. Immediate Leases: Resources are provided immediately upon request or not at all, suitable for urgent needs without flexibility.</p> <p>Haizea addresses the challenge of resource underutilization, often a downside of AR, by leveraging VMs. It allows for efficient support of ARs through resource preemption - suspending lower-priority VMs to free up resources for higher-priority needs and resuming them later. It uses optimizations such as reusing disk images across leases to minimize the impact of preparation overhead and schedules runtime overheads (like suspending, resuming, and migrating VMs) efficiently. Scheduling is based on a resource slot table, representing all physical nodes managed by Haizea over time. Best-effort leases are managed using a first-come-first-serve queue with backfilling, optimizing queue-based systems. AR leases utilize a greedy algorithm for selecting physical resources to minimize preemptions.</p> <p>There are ongoing efforts to extend OpenNebula’s capabilities, including the implementation of the libvirt interface, VM consolidation schedulers for minimizing energy consumption, and tools for service elasticity management, VM placement, public cloud interface support, and policy-driven dynamic placement optimization.</p> <p>Haizea shows that VM-based approaches with suspend/resume capabilities can address utilization issues typically associated with advance reservation (AR) use.</p> <p>```</p> <p><a href="#blog-chapters">Back to Blog Chapters</a></p> <p><a href="#blog-chapters">Back to Blog Chapters</a></p>]]></content><author><name></name></author><category term="Study"/><category term="CMU"/><summary type="html"><![CDATA[Advanced Cloud Computing Notes - SCS]]></summary></entry><entry><title type="html">Information Security - Currently Updating…</title><link href="https://ychen884.github.io/blog/2023/14741/" rel="alternate" type="text/html" title="Information Security - Currently Updating…"/><published>2023-08-29T11:00:00+00:00</published><updated>2023-08-29T11:00:00+00:00</updated><id>https://ychen884.github.io/blog/2023/14741</id><content type="html" xml:base="https://ychen884.github.io/blog/2023/14741/"><![CDATA[<h3 id="course-evaluation-final-grade-a">Course Evaluation (Final grade: A)</h3> <p>This course is structured for those who have minimal or some previous experience in computer security. It covers a broad spectrum of topics and also delves deeply into each area. The exams present a considerable challenge, and the lab requires effort, depending on the student’s prior knowledge in security. Despite having studied information security and software security during my undergraduate studies, I found the labs in this course particularly engaging. Some topics, like cryptocurrency, privacy, and security management, were especially intriguing and somewhat new to me, adding a fresh perspective to my learning experience.</p> <h3 id="reference-book">Reference Book</h3> <h4 id="security-engineering-a-guide-to-building-dependable-systems-by-ross-j-anderson">Security Engineering: A Guide to Building Dependable Systems, by Ross J. Anderson</h4>]]></content><author><name></name></author><category term="Study"/><category term="CMU"/><summary type="html"><![CDATA[Info Sec - INI]]></summary></entry><entry><title type="html">Computer Systems - Currently Updating…</title><link href="https://ychen884.github.io/blog/2023/15513/" rel="alternate" type="text/html" title="Computer Systems - Currently Updating…"/><published>2023-08-29T11:00:00+00:00</published><updated>2023-08-29T11:00:00+00:00</updated><id>https://ychen884.github.io/blog/2023/15513</id><content type="html" xml:base="https://ychen884.github.io/blog/2023/15513/"><![CDATA[<h3 id="course-evaluation-final-grade-a">Course Evaluation (Final grade: A)</h3> <p>This course is exceptional, thoroughly covering computer systems with engaging labs. The material is comprehensive yet manageable, ensuring exams and labs are not overwhelming. Highly recommended.</p>]]></content><author><name></name></author><category term="Study"/><category term="CMU"/><summary type="html"><![CDATA[Computer Science - 213/513]]></summary></entry><entry><title type="html">Fundamentals of Telecommunication Networks - Currently Upating…</title><link href="https://ychen884.github.io/blog/2023/14740/" rel="alternate" type="text/html" title="Fundamentals of Telecommunication Networks - Currently Upating…"/><published>2023-08-28T11:00:00+00:00</published><updated>2023-08-28T11:00:00+00:00</updated><id>https://ychen884.github.io/blog/2023/14740</id><content type="html" xml:base="https://ychen884.github.io/blog/2023/14740/"><![CDATA[<h3 id="course-evaluation-final-grade-a">Course Evaluation (Final grade: A)</h3> <p>This course is designed for individuals with minimal or no prior knowledge of computer networks. It delves into the intricate details of various protocols. The exams are generally easy to manage, but the labs may demand a significant amount of effort. Students should be aware that they will be sharing server resources with many others, leading to potential issues with resource contention. It also includes reviews of some state-of-the-art papers in the field.</p> <h3 id="paper-reviews">Paper reviews</h3> <p>I will upload my paper reviews here later.</p> <h3 id="reference-book">Reference Book</h3> <h4 id="computer-networking-7th-edition-james-kurose-and-keith-ross">Computer Networking 7th Edition, James Kurose, and Keith Ross</h4>]]></content><author><name></name></author><category term="Study"/><category term="CMU"/><summary type="html"><![CDATA[computer networks - INI]]></summary></entry><entry><title type="html">Link to our Game Development Project - TimeOut</title><link href="https://ychen884.github.io/blog/2023/gameDev/" rel="alternate" type="text/html" title="Link to our Game Development Project - TimeOut"/><published>2023-08-27T18:37:00+00:00</published><updated>2023-08-27T18:37:00+00:00</updated><id>https://ychen884.github.io/blog/2023/gameDev</id><content type="html" xml:base="https://ychen884.github.io/blog/2023/gameDev/"><![CDATA[<p>Check this out: https://rod233.itch.io/timeout I worked as a member of the SE team - Graphics.</p>]]></content><author><name></name></author><category term="Study"/><category term="Dev"/><summary type="html"><![CDATA[:) An interesting game dev project.]]></summary></entry><entry><title type="html">My Courses &amp;amp; Grades in UW-Madison</title><link href="https://ychen884.github.io/blog/2023/undergradCourses/" rel="alternate" type="text/html" title="My Courses &amp;amp; Grades in UW-Madison"/><published>2023-08-20T18:37:00+00:00</published><updated>2023-08-20T18:37:00+00:00</updated><id>https://ychen884.github.io/blog/2023/undergradCourses</id><content type="html" xml:base="https://ychen884.github.io/blog/2023/undergradCourses/"><![CDATA[ <p>The University of Wisconsin-Madison offers an exceptional Computer Science track for undergraduate students, enabling them to delve into various fields within the discipline. During my undergraduate studies, I concentrated on system courses, which allowed me to gain valuable insights into this specialized area.</p> <p>Below is a breakdown of the courses I undertook at UW-Madison. The advanced courses have been highlighted at the beginning of the list for emphasis. I am profoundly grateful to my instructors, whose dedication and passion have significantly shaped my academic journey. Their guidance, coupled with my relentless hard work and consistent efforts, has truly made a difference in my education.</p> <p>The courses at UW-Madison are categorized into three distinct levels:</p> <p>Elementary (E): Typically, entry-level courses designed for freshmen and sophomores. Intermediate (I): These courses are aimed at students in their sophomore to junior years. Advanced (A): Targeted at students in their junior to senior years, these courses focus on more specialized and complex topics. The education I received at UW-Madison has not only broadened my knowledge but also laid a solid foundation for my future pursuits in the field of Computer Science.</p> <p>Above 100%: Extra credits given in that course</p> <table data-toggle="table" data-url="/assets/json/table_data.json"> <thead> <tr> <th data-field="Courses">Courses</th> <th data-field="Description">Description</th> <th data-field="Final Grade">Final Grade</th> </tr> </thead> </table> <p></p> ]]></content><author><name></name></author><category term="Study"/><category term="UW-Madison"/><summary type="html"><![CDATA[:) I enjoy all the courses I took in UW-Madison.]]></summary></entry></feed>