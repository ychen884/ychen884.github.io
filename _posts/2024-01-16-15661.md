---
layout: post
title: Compiler Design Notes - Currently Upating...
date: 2024-01-30 11:00:00
description: Compiler Design Notes - SCS
tags: CMU
categories: Study
featured: true
---


<!-- inductive definition -> inference rules -->
<!-- 

If we prove the top is true, then the bottom form is true.

set of natural numbers:

------- N0
nat(0)

nat(n)
------ N1
nat(n+1)

Set of pair of numbers (x,y) that x <= y, both integers:

------   leq0
leq(0,0)

leq(n,m)
------   leq1
leq(n+1,m+1)

leq(n,m)
------   leq2
leq(n,m+1)


Prove leq(3,4) bing true

leq(0,0)
------
leq(1,1)
------
leq(2,2)
------
leq(3,3)
------   leq2
leq(3,4)


loops can happen but rule designers should make it safe 

Mode:

leq(input, output)
use inference rules to query with an input for an output.
add(n1, n2, n3)
=> n1 + n2 = n3


----------- A1
add(0,n,n)

add(m,n,k)
----------- A2
add(m+1,n,k+1)


what if add(1,1,k)? show k=2?

k = 2
----------- A1
add(0,1,k-1)
----------- A2
add(1,1,k)


use leq rules to create a set:
i, k <= 2
s0: empty set
s1: {(0,0)}
s2: {(1,1),(0,1),(0,0)}
s3: {(2,2),(1,2)...}

 -->

### Course Evaluation (Final grade: N/A)
I will add my course evaluation at the end of this semester.
### Paper reviews
I will upload my paper reviews here later.

## **Blog Chapters**
1. [Chapter 0: Overview of Compiler Design](#topic-1)
2. [Chapter 1: Instruction Selection](#topic-1.1)
3. [Chapter 2: Register Allocation](#topic-2)
3. [Chapter 3: Elaboration(after par/lex..)](#topic-3)
3. [Chapter 4: Static Semantics](#topic-4)

## **Chapter 1: Overview of Compiler Design ** <a name="topic-1"></a>



### What makes a good Compiler: metrics
- correctness
- code quality: compiled code runs fast
- efficiency: compilation runs fast
- usability: provides errors/warnings, ...

### Compiler Design
- structure compilers
- applied alg & data structures
- focus on sequential imperative programming languages 
- - not functional, parallel, distributed, OOP...
- code generation and optimization

### Organizing a compiler
#### Front
- split work into different phases
- Lexical analysis -> Token stream
- Parsing -> Abstract syntax tree (mark body of while loop...)
- Sementic analysis (type check, variable initialization)

#### Middle
- IR(intermediate representation) Generation -> Intermediate representations
- Optimize (most challenging)

#### Back
- Instruction selection -> Abstract assembly
- Register allocation -> ASM
Middle and Back has unclear distinctions

[Back to Blog Chapters](#blog-chapters)
## **Chapter 1.1: Instruction Selection ** <a name="topic-1.1"></a>
- Compiler phase
- IR tree -> abstract assembly

Example: 
```
x = 5
return x+x+x*2

->>> Instruction selection
x = 5
temp1 = x + x 
temp2 = x * 2
ret_reg = t1 + t2
ret
```
##### IR tree (more expressions, statements..)
```
Programs p ::= s1,...sn (sequence of statements)
statements s ::= x = e 
                return e

Expressions:
e ::= c int const
      x variable
      e1 ⊕ e2 binary OP (nested)
      ⊕ ::= +1 * 1 / 1 ...
```

##### Abstract Assembly (flat)
```
Program: p ::= i1, ... in (instructions)
Instructions i::= d <- s move
                = d <- s1 ⊕ s2 bin op (sometimes one of the source works as dst)
                = ret return
Operands:
    d,s ::= r register (usually* finite numbers as defined)
          = c int const
          = t temps (variables)
          = x var

```

##### Translations Expr
```
translate(e1 ⊕ e2) = translate(e1); translate(e2);
res1 ⊕ res2?
Better: 
trans(d,e): seq of instructions that stores value of e in destination d. 


e           trans(d,e)
x           d <- x
c           d <- c
e1 ⊕ e2     trans(t1, e1), trans(t2, e2), d<-t1⊕t2, (t1 and t2 are fresh temps)


```

##### Translate statements
```
trans'(s): seq of instru that inlements s
s           trans'(s)
x = e       trans(x,e)
return e    trans(ret,e) return (ret: return register)
```
##### Example
```
IR prog: 
z = (x + 1) * (y * 4)
return z

trans'(p) 
= trans'(z = (x + 1) * (y * 4)), trans'(return z)
= trans(z,(x + 1) * (y * 4)),trans(ret, z), return
= trans(t1,x+1), trans(t2,y * 4), z<- t1 * t2, ret<-z, return
= t3 <- x, t4 <- 1, t1 <- t3 + t4, t5 <- y, t6 <- 4, t2 <- t5 * t6, z <- t1*t2, ret<-z, return
Optimize? directly use x and y instead of moving them to temps

```
##### How to improve
1. Add special cases: for example c ⊕ e2
2. Optimization pass after the first pass of translation (common approach)
3. Different translation

##### Constant propagation
- goal: eliminate move t <- c, p by replacing t with c in p
- But: stop replacing t if it's written again
```
Example: 
t <- 4
x <- t+1   ---> x <- 4+1 
t <- 5
ret <- t   --NO--> ret <- 4
return 
```

##### Copy propagation
- goal: elim move d <- t,p by replacing d with t in p, But: step replacing if d is written or if t is written

```


t <- 5+1
d <- t 
x <- d+1 ----> x <- t+1
t <- 5+2
ret <- d+1 ---No---> ret <- t + 1
ret
```

##### Static Single Assignment Form 
```
- every temp is assigned at most once
- don't have to check "writes" but can replace all occurances in propagations
- Conversion to SSA -> user version nums

t <- 5+1
d <- t 
x <- d+1 ----> x <- t+1
t <- 5+2
ret <- d+1 ----No---> ret <- t + 1
ret

----->>

t0 <- 5+1
d0 <- t0
x0 <- d0+1
t1 <- 5+2
...
```

[Back to Blog Chapters](#blog-chapters)

## **Chapter 2: Register Allocation ** <a name="topic-2"></a>
- Goal: assign registers and stack locations to temps
##### X86-64: 16 registers, no temps
- stack locations, when keeping track of more variables than registers
##### Strategy
1. Store all temps on the stack (CON: inefficient, still need registers for efficiency)


```
IR trees(simplified syntax tree) 
--> Instruction selection --> ASM 
--> reg alloc --> ASM
--> x86 asm


Example: 
d <- s1 ⊕ s2
-> reg alloc

rlld <- exd * 4(rsp)
```
##### Difficulty: x86 has 15 gen purpose registers
- Goal: assign each variable a register
- may have to use stack locations and clever use of registers for variables

##### Interference:
```
x <- 14
y <- 15 
z <- x+y

x <- 14
y <- 15 + x 
ret <- 4+y
ret
if x is not used again, we can use overwrite the register for y
```

##### Rigth IR for reg alloc? 
##### 3 addr abs asm
```
d <- s1 + s2
d <- s1 / s2
...
```
##### 2 addr abs asm
```
d <- s1
d <- d + s2

d <- s1
d <- d / s2
...

```

##### abstract x86
```
MOVL S1,d
ADDL S2,d
...
IDIVL
edx:eax / s2 -> eax

MOVL s1, %eax
CLTD (sign-extends eax into edx:eax.)
----
https://stackoverflow.com/questions/17170388/trying-to-understand-the-assembly-instruction-cltd-on-x86
What this means in practice is that edx is filled with the most significant bit of eax (the sign bit). For example, if eax is 0x7F000000 edx would become 0x00000000 after cdq. And if eax is 0x80000000 edx would become 0xFFFFFFFF.
----
IDIVL s2 (edx:eax / s2)
MOVL %eax, d

```
##### Reg Alloc at 3-Addr Assem
- leave one register unassigned for later conversion (r11d)

```
For example

d <- s1 ⊕ s2
--> 
MOVL s1, %r11d
ADDL s2, %r11d
MOVL %r11d, d
(one of them has to be a register
this will always work, but may not be the optimzied solution)

```

##### Reg Alloc at 2-Addr Assem
```
For example

d <- s1 + s2
--> 
d <- s1
d <- s2 + d
```

##### How to allocate registers? 
- Goal: minimize spilling to the stack
- One method: graph-based, greedy register allocation
- - Build interference graph
```
Vertices are registers and temps
Edges indicate interference (need diff registers)

Example: 
t1  -- t2 -- t3 -- eax
        |           |
         -----------

Complexity pf deciding if two temps interfere? Undecidable
Why? Reduction to the halting problem
x <- 5
y <- 6
complex code (doesn't use x and y)
ret<- x + y
return

x and y interfere iff complex code terminates


Approximate Interference with liveness
Liveness: temp t is live at line l if t might be used in the 
following computation

For L1: work backwards
temp t is live at l if either of them is valid:
- t is read at l
- t is live at l+1 and not written at line l

Example: 
x1 <- 1            -
x2 <- 1           x1
x3 <- x1 + x2     x2,x1
x4 <- x3 + x2     x3,x2
x5 <- x4 + x3     x3,x4
ret <- x5         x5
return ret        ret register

life range of t1: 2-3
life range of x2: 3-4
..


t1 <- 1     -
t1 <- t1+1  t1
t2 <- t1    t1

Construct interf graph:
Option 1: Add edge between t1 and t2 if they have overlapping live ranges
Option 2: rule 1: For every instruction d <- s1 ⊕ s2
                        add an edge {d,t} if t is  live at the next instruction
          rule 2: For every move d <- s, add an edge {d,t} 
                  that t not in {s,d}, and is live at the next instruction


```



- Find coloring with as few colors as possible: Adjacent vertices have different colors
```
Given: Graph G = (V,E) and k colors
Question: Is there a coloring of V with k colors such that adjacent verticies have different colors
Complexity: NP complete for k >= 3 

What folllows for reg allocation? 

For a Turing-comp lang
It's undecidable for a prog if there's an equiv prog that uses k registers (and no tem)

```

- Assign colors to registers and stack locations
```
Greedy graph coloring: get a minimal coloring for most programs

Assume colors are number 1,2,3...

Let N(v) be the nbs of v
Input: G(V,E) and ordering V=v1,...,vn
Output: Coloring of V: col:V->{1,..k}

- Order matters

x5 

x4-x3-x2-x1

Order 1: x5,x4,x3,x2,x1,ret

Order 2: x1,x4,x3,x2,x5,ret


```
##### Th: There exists an ordering that produces an optimal coloring
```
How to find optimal ordering for chordal graphs?

Def: A graph is chordal if every cycle with >= 4 vertices has a chord 
(edge between two verticies in the cycle that is not in the cycle)

Example

a - b
|   |
c - d
not chordal

a - b
| / |
c - d
chordal

a - b
| x |
c - d
chordal


Intuition: how to get long cycle w/o chord?
a over lap with b and c
we want d to be not overlapping with a


```
#####  Maximum cardinality search
```
Input: G, Op: ordering of v
for each vertex in V, set wt(v) <- 0

For all v ∈ V set wt(v) ← 0
Let W ← V
For i ← 1 to n do
      Let v be a node of maximal weight in W
      Set vi ← v
      For all u ∈ W ∩ N(v) set wt(u) ← wt(u) + 1
      Set W ← W \ {v}


MCS Ordering returns: simplicial elimination ordering if G is chordal
Def: v is simplicial in G in N(v) is a clique
A simplicial vertex is one whose neighbors form a clique: every two neighbors are adjacent. 


Def: A simpl elim ordering is an ord v1, ... vn st vi is simplicial in
Gv1,..vi <- subgraph induced by v1, .. vi (picked)
```

##### Theorem 1: The graph is chordal iff it has an simplicial elim ordering

```
Proof..
```
##### Theorem 2: The greedy coloring alg finds an opt coloring if run with a simpl elim ordering
```
Proof: Let k be the number of colors used
Observations: 
- k <= max|Ni(vi)| + 1
- #min colors >= max|Ni(vi)| + 1
```

##### -> Theorem: MCS returns a sompl elem ordering iff G is chordal 



- Spill: assign remaining colors to stack loc.

```
strategies: 
1. number of uses of temps in code, higher use freq get the registers
2. incorp loop nestings
3. highest colors (high color may be used in less time, approx for 1)

```


#### Summary
1. Build the interference graph (different ways)
2. Order the vertices with MCS
3. Color with greedy alg
4. Spill if # colors > 13

#### Liveness analysis & interence rules
```
live(l,x) ~ x i live at line l
d != u
l: d <- x ⊕ y live(l+1, u)
--------------------------
      live(l, u)


l: d<- x ⊕ y
------------------
    live(l, x)
    live(l, y)

l: return
------------------
   live(l, ret)


l: x <- c
live(l+1, u), x!=u
-------------------
      live(l,u)

l: x<-y, u!=x
live(l+1, u)
--------------
live(l,u)


l:x<-y
-------
live(l,y)

Using derivation tree to prove if x live at line l

```

##### General Saturation Alg
```
Can be used for all predicates
1: start with empty set of facts <- derived predicates
2: pick arg (here: l and t) and a rule with live(l,t) in the conclusion
so that the premises are already facts
3: Repeat until no facts can be derived

Will always stop
```


##### Refactoring liveness rules
```
use(l,x)
---------
live(l,x)

*: l' is a possible succesor
live(l'x) succ(l,l') ~def(l,x) 
---------------------------------
      live(l,x)

```

##### Need to define:
```
use(l,x) ~ x is used at l 
def(l,x) ~ x is def at l
succ(l,l') ~ l' can be a succ of l
```

##### Example 
```
l: d <- x ⊕ y
-------------
use(l,x)
use(l,y)
def(l,d)
succ(l,l+1)
```


##### Adding loops and conditionals:
```
i = l: d <- x ⊕ y
.
.
.
l: goto l' (uncond jump)
l: if(x?c) then lt then lt else lf(cond jump)

New rules:

l: goto l'
-----------
succ(l,l')

l: if(x'c) then lt
else lf
-------------------
succ(l,lt)
succ(l,lf)
use(l,x)


Keep doing iterations until we cannot add more new to the liveness sets
pass 1, pass 2, ...

```

##### Interference graph
```
1. Overlapping live ranges

live(l,x) live(l,y)
-------------------
inter(x,y)

But doesn't work in the presence of that code dead code

Example: 
a <- 1
b <- 2
ret <- a
return


2. Assignment based
More sparse

l: x <- y ⊕ z live(l+1, u), u!=x
---------------------------------
inter(x,u)

l:x<-y, y!=u
live(l+1, u) x!=u
------------------
inter(x,u)

l: x<-c, u!=x
live(l+1, u)
--------------
inter(x,u)
```

## Chapter 3: Elaboration <a name="topic-3"></a>

##### Goal: minimal repr and clear of progr
- remove syntactic sugar
- make scope explicit


```
Parsing -> Parse tree -> elaboration -> AST(<-Semantic analysis)

Example: 
turn for lops into while loops

for(int x=4, x<8128, x++){
      y = y+x
}
------> elab
use declaration(x,int,s)
{int x=4; while(x<8128)..}
decl(x, int, while(x<8218){..})

// Before elaboration
for (int x = 4; x < 30; x++) { y = y + x }


// After elaboration
{
int x = 4;
while (x < 30) { y = y + x; x += 1 }
}

abstract syntax

declare(x, int,seq(assign(x, 4),
                  while(x < 30,
                  seq(assign(y, y + x), assign(x, x + 1)))))

The extra scope is necessary
Rather than continuing to perform manipulations on surface syntax, we introduce the BNF of an elaborated abstract syntax


Expressions e ::= n | x | e1 ⊕ e2 | e1 /o e2 | f(e1, . . . , en)
| e1 ? e2 | !e | e1 && e2 | e1 || e2

/0:  potentially effectful operators (such as division or shift, which could raise an exception)

⊕ for effect-free operators
? for comparison operators returning a boolean, !, &&, and || for logical negation, conjunction, and disjunction, respectively

Statements s ::= 
declare(x, τ, s) | 
assign(x, e) | 
if(e, s1, s2) | 
while(e, s)| 
return(e) | 
nop | 
seq(s1, s2)


```
##### Inf rule
```
<tp> τ
<ident> x
<exp1> e1
<exp2> e2
<stmt1> s1
<stmt2> s2
-----------------------------------------------------
for (<tp> <ident> = <exp1>; <exp2>; <stmt1>) <stmt2>
 declare(x, τ,while(e1,seq(s2, s1)))

When we want to translate a for loop that
matches the pattern at the bottom, we have to do six things: 
elaborate the type,
elaborate the identifier, 
elaborate both expressions, 
elaborate the afterthought, and
then elaborate the loop body. 
x++ -> assign(x, x + 1)
make sure any nested for loops in <stmt2>, the body of our for loop, are elaborated

```
##### WHy IR tree
-  isolate potentially effectful expressions, making their order of execution explicit.simplifies instruction selection and also means that the remaining pure expressions can be optimized much more effectively.
- make the control flow explicit in the form of conditional or unconditional branches, which is closer to the assembly language target and allows us to apply standard program analyses based on an explicit control flow graph.
```
Pure Expressions p ::= n | x | p1 ⊕ p2

Commands c 
::= 
x ← p
| x ← p1 /0 p2
| x ← f(p1, . . . , pn)
| if (p1 ? p2) then lt else lf
| goto l
| l :
| return(p)
Programs r ::= c1 ; . . . ; cn


```

#####  Translating Expressions
```
tr(e) = <ˇe, eˆ>
where eˇ is a sequence of commands r that we need to write down to compute the
effects of e and eˆ is a pure expression p that we can use to compute the value of e back up. 


tr(n) = <·, n>
tr(x) = <·, x>
tr(e1 ⊕ e2) = <(ˇe1 ; ˇe2), eˆ1 ⊕ eˆ2>?


```

##### Translating Statements

```
tr(assign(x, e)) = ˇe ; x ← eˆ
tr(return(e)) = ˇe ; return(ˆe)
tr(nop) = ·
tr(seq(s1, s2)) = ˇs1 ; ˇs2


tr(if(e, s1, s2)) = ˇe ;
if (ˆe != 0) then l1 else l2 ;
l1 : ˇs1 ;
goto l3 ;
l2 : ˇs2 ;
l3 :



tr(while(e, s)) = l1 : ˇe;
if (ˆe != 0) then l2 else l3 ;
l2 : ˇs ; goto l1;
l3 : 
```


##### Translating Boolean Expressions
```
cp(e1 ? e2, l, l') = 
ˇe1 ; ˇe2 ;
if (ˆe1 ? eˆ2) then l else l'


cp(!e, l, l') = cp(e, l', l)

cp(e1 && e2, l, l') = 
cp(e1, l2, l');
l2 : cp(e2, l, l')


cp(e1 || e2, l, l') = left to the reader

cp(0, l, l') = goto l'

cp(1, l, l') = goto l

cp(e, l, l') = 
ˇe ;
if (ˆe != 0) then l else l'


tr(if(b, s1, s2)) = cp(b, l1, l2)
l1 : tr(s1) ; goto l3
l2 : tr(s2) ; goto l3
l3 :


tr(e) = <cp(e, l1, l2);
l1 : t ← 1 ; goto l3
l2 : t ← 0 ; goto l3
l3 :
, t>
```
##### Extended basic blocks

```
 instead of basic blocks being sequences of commands ending
in a jump, they are trees of commands that branch at conditional statements and
have unconditional jumps (goto or return) as their leaves
```
## Chapter 4: Static Semantics <a name="topic-4"></a>

#####  abstract syntax
```
After lexing and parsing, a compiler will usually apply elaboration to translate the parse tree to a high-level intermediate form often called abstract syntax. Then we verify that the abstract syntax satisfies the requirements of the static semantics.


C0:
• Initialization: variables must be defined before they are used.
• Proper returns: functions that return a value must have an explicit return statement on every control flow path starting at the beginning of the function.
• Types: the program must be well-typed.
```
#####  Abstract Syntax as defined in last chap
##### Def
```
we would like to raise an error if there is a possibility that
an unitialized variable may be used. 

may-property
use(e1/2, x)
-----------
use(e1 && e2, x)

use(e1/2, x)
-----------
use(e1 ⊕ e2, x)


must-property
def(s, x) if the execution of statement s will define x.


--------------------
def(assign(x, e), x)



def(s1, x) def(s2, x)
-----------------------
def(if(e, s1, s2), x)

A conditional only defines a variable if is it defined along
 both branches, and a while loop does not define any variable 
 (since the body may never be executed).

def(s1/2, x)
-----------------
def(seq(s1, s2), x)

def(s, x) y != x
---------------------
def(decl(y, τ, s), x)
x is declared at most once on a control-flow
path. 

--------------------
def(return(e), x)
Since a return statement will never
pass the control flow to the next instruction, any subsequent statements are unreachable. It is therefore permissible to claim that all variables currently in scope have been defined. 
```
###### Liveness

```

We observe that liveness is indeed a may-property, since a variable is live in a conditional if is used in the condition or live in one or more of the branches.


use(e, x)
----------------
live(assign(y, e), x)


use(e, x)
----------------
live(if(e, s1, s2), x)


use(s1, x)
----------------
live(if(e, s1, s2), x)


use(s2, x)
----------------
live(if(e, s1, s2), x)

use(e, x)
----------------
live(while(e, s), x)

live(s, x)
----------------
live(while(e, s), x)

use(e, x)
----------------
live(return(e), x)

no rule for
live(nop, x)

live(x, s) y != x
----------------
live(decl(y, τ, s), x)


live(s1, x)
----------------
live(seq(s1, s2), x)

¬def(s1, x) live(s2, x)
----------------
live(seq(s1, s2), x)

```
###### Initialization

```
captures the general condition.


should be read from the premises
to the conclusion.
decl(x, τ, s) in p   live(s, x)
------------------------------
error


from the conclusion to the premises


------------------------------
init(nop)


init(s1) init(s2)
------------------------------
init(seq(s1, s2))


init(s) ¬live(s, x)
------------------------------
init(decl(x, τ, s))
```
#####  From Judgments to Functions
```
init : stm → bool
init(nop) = T
init(seq(s1, s2)) = init(s1) ∧ init(s2)
init(decl(x, τ, s)) = init(s) ∧ ¬live(s, x)

live(nop, x) = ⊥
live(seq(s1, s2), x) = live(s1, x) ∨ (¬def(s1, x) ∧ live(s2, x))
live(decl(y, τ, s), x) = y != x ∧ live(x, s)
. . .

...
init(δ, s, δ'): 
assuming all the variables in δ are defined when s is reached, 
no uninitialized variable will be referenced and after its execution 
all the variables in δ' will be defined.

use(δ, e): e will only reference variables defined in δ.

δ |- s ⇒ δ' for init(δ, s, δ').
δ |- e for use(δ, e).

δ ⊢ s1 ⇒ δ1
δ1 ⊢ s2 ⇒ δ2
______________
δ ⊢ seq(s1, s2) ⇒ δ2


δ ⊢ e
_________
δ ⊢ assign(x, e) ⇒ δ ∪ {x}


δ ⊢ e
δ ⊢ s1 ⇒ δ1
δ ⊢ s2 ⇒ δ2
_________________
δ ⊢ if(e, s1, s2) ⇒ δ1 ∩ δ2


δ ⊢ e
δ ⊢ s ⇒ δ'
_________
δ ⊢ while(e, s) ⇒ δ



In particular, declare(x, τ, s) means that the variable x is declared (only) within the statement s.
δ ⊢ s ⇒ δ'
___________
δ ⊢ decl(y, τ, s) ⇒ δ' - {y}


δ ⊢ e
_________
δ ⊢ return(e) ⇒ {x | x in scope}



Typing Judgment for Statements:
The notation Γ ⊢ s : [τ] is a typing judgment for statements,
where Γ is the type environment (context), 
s is a statement, 
and τ is the type. 
This notation signifies that the statement s is well-typed within the 
context Γ and ultimately returns a value of type τ
```





[Back to Blog Chapters](#blog-chapters)

